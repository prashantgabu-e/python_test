from langchain import OpenAI
from langchain.chains.llm import LLMChain
from langchain_core.prompts import PromptTemplate

llm = OpenAI(model="gpt-3.5-turbo", openai_api_key="KEY_HERE")

# Prompt template can be enhanced to get finer output
prompt = PromptTemplate(input_variables=["text"],
                        template="Summarize the data and create bullet points from the content: {text}")

chain = LLMChain(llm=llm, prompt=prompt)

with open("data_file.txt", "rb") as content_file:
    text = content_file.read()

# This will print the summary generated by the LLM from the text file which we have given.
summary = chain.run(text)
